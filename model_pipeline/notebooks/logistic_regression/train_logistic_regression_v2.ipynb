{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Logistic Regression V2 Training\n",
    "## With Enriched Features (User, Product, Brand aggregates)\n",
    "\n",
    "This notebook trains Logistic Regression with the new V2 features:\n",
    "- User behavior features (views, carts, purchases, conversion rates)\n",
    "- Product features (popularity, conversion rates)\n",
    "- Brand features (purchase rate)\n",
    "- Price comparison features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## 1. Load V2 Data with Enriched Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOGISTIC REGRESSION V2 TRAINING (With Enriched Features)\n",
      "======================================================================\n",
      "\n",
      "[1/6] Loading V2 data with enriched features...\n",
      "Loading from: /Users/jky/Library/CloudStorage/GoogleDrive-lethanhquang094@gmail.com/My Drive/FPT/Semester_4/DAP391m/Cart-to-Purchase-Conversion-Prediction/data_pipeline/propensity_feature_store/propensity_features/feature_repo/data/processed_purchase_propensity_data_v2.parquet\n",
      "Dataset shape: (2929997, 31)\n",
      "Columns: ['user_id', 'product_id', 'event_timestamp', 'created_timestamp', 'category_code_level1', 'category_code_level2', 'brand', 'event_weekday', 'price', 'activity_count', 'event_hour', 'user_total_events', 'user_total_views', 'user_total_carts', 'user_total_purchases', 'user_view_to_cart_rate', 'user_cart_to_purchase_rate', 'user_avg_purchase_price', 'user_unique_products', 'user_unique_categories', 'product_total_events', 'product_total_views', 'product_total_carts', 'product_total_purchases', 'product_view_to_cart_rate', 'product_cart_to_purchase_rate', 'product_unique_buyers', 'brand_purchase_rate', 'price_vs_user_avg', 'price_vs_category_avg', 'is_purchased']\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"LOGISTIC REGRESSION V2 TRAINING (With Enriched Features)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n[1/6] Loading V2 data with enriched features...\")\n",
    "\n",
    "# Define path - adjust based on notebook location\n",
    "parquet_path = Path(\"../../../data_pipeline/propensity_feature_store/propensity_features/feature_repo/data/processed_purchase_propensity_data_v2.parquet\")\n",
    "parquet_path = parquet_path.resolve()\n",
    "\n",
    "print(f\"Loading from: {parquet_path}\")\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "explore-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>created_timestamp</th>\n",
       "      <th>category_code_level1</th>\n",
       "      <th>category_code_level2</th>\n",
       "      <th>brand</th>\n",
       "      <th>event_weekday</th>\n",
       "      <th>price</th>\n",
       "      <th>activity_count</th>\n",
       "      <th>...</th>\n",
       "      <th>product_total_views</th>\n",
       "      <th>product_total_carts</th>\n",
       "      <th>product_total_purchases</th>\n",
       "      <th>product_view_to_cart_rate</th>\n",
       "      <th>product_cart_to_purchase_rate</th>\n",
       "      <th>product_unique_buyers</th>\n",
       "      <th>brand_purchase_rate</th>\n",
       "      <th>price_vs_user_avg</th>\n",
       "      <th>price_vs_category_avg</th>\n",
       "      <th>is_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94566147</td>\n",
       "      <td>1005007</td>\n",
       "      <td>2019-11-12 15:04:08</td>\n",
       "      <td>2026-01-20 15:40:18.521933</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>1</td>\n",
       "      <td>93.78</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>26505</td>\n",
       "      <td>2589</td>\n",
       "      <td>654</td>\n",
       "      <td>0.097680</td>\n",
       "      <td>0.252607</td>\n",
       "      <td>548</td>\n",
       "      <td>0.262642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.221107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176495092</td>\n",
       "      <td>6301929</td>\n",
       "      <td>2019-11-08 14:01:42</td>\n",
       "      <td>2026-01-20 15:40:18.521933</td>\n",
       "      <td>appliances</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>polaris</td>\n",
       "      <td>4</td>\n",
       "      <td>28.31</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.303095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.120976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239198635</td>\n",
       "      <td>1003942</td>\n",
       "      <td>2019-11-09 15:29:59</td>\n",
       "      <td>2026-01-20 15:40:18.521933</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>5</td>\n",
       "      <td>187.24</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6618</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>19</td>\n",
       "      <td>0.262642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.441459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>239198635</td>\n",
       "      <td>1003942</td>\n",
       "      <td>2019-11-09 15:30:54</td>\n",
       "      <td>2026-01-20 15:40:18.521933</td>\n",
       "      <td>electronics</td>\n",
       "      <td>smartphone</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>5</td>\n",
       "      <td>187.24</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6618</td>\n",
       "      <td>84</td>\n",
       "      <td>22</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>19</td>\n",
       "      <td>0.262642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.441459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269003139</td>\n",
       "      <td>6000032</td>\n",
       "      <td>2019-11-26 14:38:48</td>\n",
       "      <td>2026-01-20 15:40:18.521933</td>\n",
       "      <td>auto</td>\n",
       "      <td>accessories</td>\n",
       "      <td>cenmax</td>\n",
       "      <td>1</td>\n",
       "      <td>66.39</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>9319</td>\n",
       "      <td>291</td>\n",
       "      <td>84</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>0.288660</td>\n",
       "      <td>72</td>\n",
       "      <td>0.291525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.443217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  product_id     event_timestamp          created_timestamp  \\\n",
       "0   94566147     1005007 2019-11-12 15:04:08 2026-01-20 15:40:18.521933   \n",
       "1  176495092     6301929 2019-11-08 14:01:42 2026-01-20 15:40:18.521933   \n",
       "2  239198635     1003942 2019-11-09 15:29:59 2026-01-20 15:40:18.521933   \n",
       "3  239198635     1003942 2019-11-09 15:30:54 2026-01-20 15:40:18.521933   \n",
       "4  269003139     6000032 2019-11-26 14:38:48 2026-01-20 15:40:18.521933   \n",
       "\n",
       "  category_code_level1 category_code_level2    brand  event_weekday   price  \\\n",
       "0          electronics           smartphone   xiaomi              1   93.78   \n",
       "1           appliances              kitchen  polaris              4   28.31   \n",
       "2          electronics           smartphone   xiaomi              5  187.24   \n",
       "3          electronics           smartphone   xiaomi              5  187.24   \n",
       "4                 auto          accessories   cenmax              1   66.39   \n",
       "\n",
       "   activity_count  ...  product_total_views  product_total_carts  \\\n",
       "0               3  ...                26505                 2589   \n",
       "1               3  ...                  144                    3   \n",
       "2               3  ...                 6618                   84   \n",
       "3               5  ...                 6618                   84   \n",
       "4              12  ...                 9319                  291   \n",
       "\n",
       "   product_total_purchases  product_view_to_cart_rate  \\\n",
       "0                      654                   0.097680   \n",
       "1                        1                   0.020833   \n",
       "2                       22                   0.012693   \n",
       "3                       22                   0.012693   \n",
       "4                       84                   0.031227   \n",
       "\n",
       "   product_cart_to_purchase_rate  product_unique_buyers  brand_purchase_rate  \\\n",
       "0                       0.252607                    548             0.262642   \n",
       "1                       0.333333                      1             0.303095   \n",
       "2                       0.261905                     19             0.262642   \n",
       "3                       0.261905                     19             0.262642   \n",
       "4                       0.288660                     72             0.291525   \n",
       "\n",
       "   price_vs_user_avg  price_vs_category_avg  is_purchased  \n",
       "0                1.0               0.221107             0  \n",
       "1                1.0               0.120976             0  \n",
       "2                1.0               0.441459             0  \n",
       "3                1.0               0.441459             0  \n",
       "4                1.0               0.443217             0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "user_id                                   int64\n",
      "product_id                                int64\n",
      "event_timestamp                  datetime64[ns]\n",
      "created_timestamp                datetime64[us]\n",
      "category_code_level1                     object\n",
      "category_code_level2                     object\n",
      "brand                                    object\n",
      "event_weekday                             int64\n",
      "price                                   float64\n",
      "activity_count                            int64\n",
      "event_hour                                int64\n",
      "user_total_events                         int64\n",
      "user_total_views                          int64\n",
      "user_total_carts                          int64\n",
      "user_total_purchases                      int64\n",
      "user_view_to_cart_rate                  float64\n",
      "user_cart_to_purchase_rate              float64\n",
      "user_avg_purchase_price                 float64\n",
      "user_unique_products                      int64\n",
      "user_unique_categories                    int64\n",
      "product_total_events                      int64\n",
      "product_total_views                       int64\n",
      "product_total_carts                       int64\n",
      "product_total_purchases                   int64\n",
      "product_view_to_cart_rate               float64\n",
      "product_cart_to_purchase_rate           float64\n",
      "product_unique_buyers                     int64\n",
      "brand_purchase_rate                     float64\n",
      "price_vs_user_avg                       float64\n",
      "price_vs_category_avg                   float64\n",
      "is_purchased                              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Explore the data\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-header",
   "metadata": {},
   "source": [
    "## 2. Define Features (V2 - Extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "define-features",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/6] Preparing features...\n",
      "Numerical features: 23\n",
      "Categorical features: 3\n",
      "Total features: 26\n",
      "\n",
      "Numerical features list:\n",
      "  1. price\n",
      "  2. activity_count\n",
      "  3. event_weekday\n",
      "  4. event_hour\n",
      "  5. user_total_events\n",
      "  6. user_total_views\n",
      "  7. user_total_carts\n",
      "  8. user_total_purchases\n",
      "  9. user_view_to_cart_rate\n",
      "  10. user_cart_to_purchase_rate\n",
      "  11. user_avg_purchase_price\n",
      "  12. user_unique_products\n",
      "  13. user_unique_categories\n",
      "  14. product_total_events\n",
      "  15. product_total_views\n",
      "  16. product_total_carts\n",
      "  17. product_total_purchases\n",
      "  18. product_view_to_cart_rate\n",
      "  19. product_cart_to_purchase_rate\n",
      "  20. product_unique_buyers\n",
      "  21. brand_purchase_rate\n",
      "  22. price_vs_user_avg\n",
      "  23. price_vs_category_avg\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/6] Preparing features...\")\n",
    "\n",
    "# Numerical features (original + new)\n",
    "NUMERICAL_FEATURES = [\n",
    "    # Original\n",
    "    \"price\",\n",
    "    \"activity_count\",\n",
    "    \"event_weekday\",\n",
    "    # New: Hour\n",
    "    \"event_hour\",\n",
    "    # New: User features\n",
    "    \"user_total_events\",\n",
    "    \"user_total_views\",\n",
    "    \"user_total_carts\",\n",
    "    \"user_total_purchases\",\n",
    "    \"user_view_to_cart_rate\",\n",
    "    \"user_cart_to_purchase_rate\",\n",
    "    \"user_avg_purchase_price\",\n",
    "    \"user_unique_products\",\n",
    "    \"user_unique_categories\",\n",
    "    # New: Product features\n",
    "    \"product_total_events\",\n",
    "    \"product_total_views\",\n",
    "    \"product_total_carts\",\n",
    "    \"product_total_purchases\",\n",
    "    \"product_view_to_cart_rate\",\n",
    "    \"product_cart_to_purchase_rate\",\n",
    "    \"product_unique_buyers\",\n",
    "    # New: Brand & Price comparison\n",
    "    \"brand_purchase_rate\",\n",
    "    \"price_vs_user_avg\",\n",
    "    \"price_vs_category_avg\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\"brand\", \"category_code_level1\", \"category_code_level2\"]\n",
    "TARGET = \"is_purchased\"\n",
    "ALL_FEATURES = NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
    "\n",
    "print(f\"Numerical features: {len(NUMERICAL_FEATURES)}\")\n",
    "print(f\"Categorical features: {len(CATEGORICAL_FEATURES)}\")\n",
    "print(f\"Total features: {len(ALL_FEATURES)}\")\n",
    "\n",
    "print(\"\\nNumerical features list:\")\n",
    "for i, f in enumerate(NUMERICAL_FEATURES, 1):\n",
    "    print(f\"  {i}. {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prepare-xy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution:\n",
      "  Class 0 (Not Purchased): 2,170,105 (74.07%)\n",
      "  Class 1 (Purchased):     759,892 (25.93%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare X and y\n",
    "X = df[ALL_FEATURES].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "# Convert categorical columns to string type\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    X[col] = X[col].astype(str)\n",
    "\n",
    "# Fill any remaining nulls\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Class 0 (Not Purchased): {(y == 0).sum():,} ({(y == 0).mean() * 100:.2f}%)\")\n",
    "print(f\"  Class 1 (Purchased):     {(y == 1).sum():,} ({(y == 1).mean() * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-header",
   "metadata": {},
   "source": [
    "## 3. Train/Validation/Test Split (64%/16%/20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "split-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/6] Splitting data (64%/16%/20%)...\n",
      "Training set:   1,875,197 samples (64.0%)\n",
      "Validation set: 468,800 samples (16.0%)\n",
      "Test set:       586,000 samples (20.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/6] Splitting data (64%/16%/20%)...\")\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Training set:   {X_train.shape[0]:,} samples ({X_train.shape[0] / len(X) * 100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]:,} samples ({X_val.shape[0] / len(X) * 100:.1f}%)\")\n",
    "print(f\"Test set:       {X_test.shape[0]:,} samples ({X_test.shape[0] / len(X) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "create-preprocessor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor created!\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUMERICAL_FEATURES),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(\n",
    "                handle_unknown=\"ignore\", sparse_output=False, max_categories=100\n",
    "            ),\n",
    "            CATEGORICAL_FEATURES,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "print(\"Preprocessor created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tuning-header",
   "metadata": {},
   "source": [
    "## 4. Regularization Tuning on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/6] Tuning regularization parameter C...\n",
      "--------------------------------------------------\n",
      "\n",
      "Training with C=0.001... Done (7.0s)\n",
      "  Accuracy: 0.8109 | F1: 0.7751 | AUC-ROC: 0.8991\n",
      "\n",
      "Training with C=0.01... Done (7.6s)\n",
      "  Accuracy: 0.8112 | F1: 0.7754 | AUC-ROC: 0.8992\n",
      "\n",
      "Training with C=0.1... Done (7.3s)\n",
      "  Accuracy: 0.8112 | F1: 0.7754 | AUC-ROC: 0.8992\n",
      "\n",
      "Training with C=1... Done (6.4s)\n",
      "  Accuracy: 0.8112 | F1: 0.7754 | AUC-ROC: 0.8992\n",
      "\n",
      "Training with C=10... Done (7.1s)\n",
      "  Accuracy: 0.8112 | F1: 0.7754 | AUC-ROC: 0.8992\n",
      "\n",
      "Training with C=100... Done (6.4s)\n",
      "  Accuracy: 0.8112 | F1: 0.7754 | AUC-ROC: 0.8992\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/6] Tuning regularization parameter C...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "C_VALUES = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "tuning_results = []\n",
    "\n",
    "for C in C_VALUES:\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nTraining with C={C}...\", end=\" \", flush=True)\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    C=C,\n",
    "                    solver=\"lbfgs\",\n",
    "                    max_iter=1000,\n",
    "                    class_weight=\"balanced\",\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    y_val_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "    val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    result = {\n",
    "        \"C\": C,\n",
    "        \"accuracy\": val_accuracy,\n",
    "        \"f1_macro\": val_f1,\n",
    "        \"auc_roc\": val_auc,\n",
    "        \"pipeline\": pipeline,\n",
    "    }\n",
    "    tuning_results.append(result)\n",
    "\n",
    "    print(f\"Done ({elapsed:.1f}s)\")\n",
    "    print(f\"  Accuracy: {val_accuracy:.4f} | F1: {val_f1:.4f} | AUC-ROC: {val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "select-best",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Best C: 100 (AUC-ROC: 0.8992)\n",
      "\n",
      "Tuning Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.810907</td>\n",
       "      <td>0.775121</td>\n",
       "      <td>0.899068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.811160</td>\n",
       "      <td>0.775410</td>\n",
       "      <td>0.899182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.811156</td>\n",
       "      <td>0.775363</td>\n",
       "      <td>0.899197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.811160</td>\n",
       "      <td>0.775370</td>\n",
       "      <td>0.899195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.811160</td>\n",
       "      <td>0.775394</td>\n",
       "      <td>0.899182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.811184</td>\n",
       "      <td>0.775410</td>\n",
       "      <td>0.899212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C  Accuracy  F1 Macro   AUC-ROC\n",
       "0    0.001  0.810907  0.775121  0.899068\n",
       "1    0.010  0.811160  0.775410  0.899182\n",
       "2    0.100  0.811156  0.775363  0.899197\n",
       "3    1.000  0.811160  0.775370  0.899195\n",
       "4   10.000  0.811160  0.775394  0.899182\n",
       "5  100.000  0.811184  0.775410  0.899212"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select best model\n",
    "best_result = max(tuning_results, key=lambda x: x[\"auc_roc\"])\n",
    "best_C = best_result[\"C\"]\n",
    "best_pipeline = best_result[\"pipeline\"]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(f\"Best C: {best_C} (AUC-ROC: {best_result['auc_roc']:.4f})\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nTuning Summary:\")\n",
    "tuning_df = pd.DataFrame([\n",
    "    {\"C\": r[\"C\"], \"Accuracy\": r[\"accuracy\"], \"F1 Macro\": r[\"f1_macro\"], \"AUC-ROC\": r[\"auc_roc\"]}\n",
    "    for r in tuning_results\n",
    "])\n",
    "display(tuning_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-training-header",
   "metadata": {},
   "source": [
    "## 5. Final Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "final-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/6] Final training on train+validation...\n",
      "Final training set: 2,343,997 samples\n",
      "Training complete (10.4s)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/6] Final training on train+validation...\")\n",
    "\n",
    "X_train_final = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_final = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "print(f\"Final training set: {len(X_train_final):,} samples\")\n",
    "\n",
    "final_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUMERICAL_FEATURES),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(\n",
    "                handle_unknown=\"ignore\", sparse_output=False, max_categories=100\n",
    "            ),\n",
    "            CATEGORICAL_FEATURES,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "final_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", final_preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(\n",
    "                C=best_C,\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=1000,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "final_pipeline.fit(X_train_final, y_train_final)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training complete ({train_time:.1f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "evaluate-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "==================================================\n",
      "TEST SET RESULTS (V2 Features)\n",
      "==================================================\n",
      "Accuracy:  0.8116\n",
      "Precision: 0.7616 (macro)\n",
      "Recall:    0.8062 (macro)\n",
      "F1-Score:  0.7759 (macro)\n",
      "AUC-ROC:   0.8996\n",
      "\n",
      "Per-Class Metrics:\n",
      "  Class 0 (Not Purchased):\n",
      "    Precision: 0.9193\n",
      "    Recall:    0.8174\n",
      "    F1-Score:  0.8654\n",
      "  Class 1 (Purchased):\n",
      "    Precision: 0.6039\n",
      "    Recall:    0.7951\n",
      "    F1-Score:  0.6864\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "y_test_pred = final_pipeline.predict(X_test)\n",
    "y_test_proba = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate all metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision_macro = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "test_recall_macro = recall_score(y_test, y_test_pred, average=\"macro\")\n",
    "test_f1_macro = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "# Per-class metrics\n",
    "test_precision_per_class = precision_score(y_test, y_test_pred, average=None)\n",
    "test_recall_per_class = recall_score(y_test, y_test_pred, average=None)\n",
    "test_f1_per_class = f1_score(y_test, y_test_pred, average=None)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TEST SET RESULTS (V2 Features)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision_macro:.4f} (macro)\")\n",
    "print(f\"Recall:    {test_recall_macro:.4f} (macro)\")\n",
    "print(f\"F1-Score:  {test_f1_macro:.4f} (macro)\")\n",
    "print(f\"AUC-ROC:   {test_auc_roc:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Class Metrics:\")\n",
    "print(f\"  Class 0 (Not Purchased):\")\n",
    "print(f\"    Precision: {test_precision_per_class[0]:.4f}\")\n",
    "print(f\"    Recall:    {test_recall_per_class[0]:.4f}\")\n",
    "print(f\"    F1-Score:  {test_f1_per_class[0]:.4f}\")\n",
    "print(f\"  Class 1 (Purchased):\")\n",
    "print(f\"    Precision: {test_precision_per_class[1]:.4f}\")\n",
    "print(f\"    Recall:    {test_recall_per_class[1]:.4f}\")\n",
    "print(f\"    F1-Score:  {test_f1_per_class[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "  [[TN=354,762  FP=79,259]\n",
      "   [FN=31,143  TP=120,836]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Purchased       0.92      0.82      0.87    434021\n",
      "    Purchased       0.60      0.80      0.69    151979\n",
      "\n",
      "     accuracy                           0.81    586000\n",
      "    macro avg       0.76      0.81      0.78    586000\n",
      " weighted avg       0.84      0.81      0.82    586000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"  [[TN={cm[0, 0]:,}  FP={cm[0, 1]:,}]\")\n",
    "print(f\"   [FN={cm[1, 0]:,}  TP={cm[1, 1]:,}]]\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Not Purchased\", \"Purchased\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "validation-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Metrics (for comparison):\n",
      "  Accuracy:  0.8112\n",
      "  Precision: 0.7611 (macro)\n",
      "  Recall:    0.8057 (macro)\n",
      "  F1-Score:  0.7754 (macro)\n",
      "  AUC-ROC:   0.8992\n"
     ]
    }
   ],
   "source": [
    "# Get validation metrics\n",
    "y_val_pred_best = best_pipeline.predict(X_val)\n",
    "y_val_proba_best = best_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred_best)\n",
    "val_precision_macro = precision_score(y_val, y_val_pred_best, average=\"macro\")\n",
    "val_recall_macro = recall_score(y_val, y_val_pred_best, average=\"macro\")\n",
    "val_f1_macro = f1_score(y_val, y_val_pred_best, average=\"macro\")\n",
    "val_auc_roc = roc_auc_score(y_val, y_val_proba_best)\n",
    "\n",
    "val_precision_per_class = precision_score(y_val, y_val_pred_best, average=None)\n",
    "val_recall_per_class = recall_score(y_val, y_val_pred_best, average=None)\n",
    "val_f1_per_class = f1_score(y_val, y_val_pred_best, average=None)\n",
    "\n",
    "print(\"Validation Set Metrics (for comparison):\")\n",
    "print(f\"  Accuracy:  {val_accuracy:.4f}\")\n",
    "print(f\"  Precision: {val_precision_macro:.4f} (macro)\")\n",
    "print(f\"  Recall:    {val_recall_macro:.4f} (macro)\")\n",
    "print(f\"  F1-Score:  {val_f1_macro:.4f} (macro)\")\n",
    "print(f\"  AUC-ROC:   {val_auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 6. Save Metrics to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "save-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/6] Saving metrics to JSON...\n",
      "Metrics saved to: /Users/jky/Library/CloudStorage/GoogleDrive-lethanhquang094@gmail.com/My Drive/FPT/Semester_4/DAP391m/Cart-to-Purchase-Conversion-Prediction/model_pipeline/metrics/logistic_regression_v2_metrics.json\n",
      "\n",
      "======================================================================\n",
      "TRAINING COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[6/6] Saving metrics to JSON...\")\n",
    "\n",
    "metrics = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"version\": \"v2_enriched_features\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"hyperparameters\": {\n",
    "        \"best_C\": best_C,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 1000,\n",
    "        \"class_weight\": \"balanced\",\n",
    "    },\n",
    "    \"data_split\": {\n",
    "        \"train_size\": int(len(X_train)),\n",
    "        \"val_size\": int(len(X_val)),\n",
    "        \"test_size\": int(len(X_test)),\n",
    "        \"train_val_size\": int(len(X_train_final)),\n",
    "        \"total_size\": int(len(X)),\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"numerical\": NUMERICAL_FEATURES,\n",
    "        \"categorical\": CATEGORICAL_FEATURES,\n",
    "        \"total_count\": len(ALL_FEATURES),\n",
    "        \"preprocessing\": {\n",
    "            \"numerical\": \"StandardScaler\",\n",
    "            \"categorical\": \"OneHotEncoder (max_categories=100)\",\n",
    "        },\n",
    "    },\n",
    "    \"regularization_tuning\": [\n",
    "        {\n",
    "            \"C\": r[\"C\"],\n",
    "            \"val_accuracy\": round(r[\"accuracy\"], 4),\n",
    "            \"val_f1_macro\": round(r[\"f1_macro\"], 4),\n",
    "            \"val_auc_roc\": round(r[\"auc_roc\"], 4),\n",
    "        }\n",
    "        for r in tuning_results\n",
    "    ],\n",
    "    \"validation_metrics\": {\n",
    "        \"accuracy\": round(val_accuracy, 4),\n",
    "        \"precision\": {\n",
    "            \"macro\": round(val_precision_macro, 4),\n",
    "            \"class_0\": round(float(val_precision_per_class[0]), 4),\n",
    "            \"class_1\": round(float(val_precision_per_class[1]), 4),\n",
    "        },\n",
    "        \"recall\": {\n",
    "            \"macro\": round(val_recall_macro, 4),\n",
    "            \"class_0\": round(float(val_recall_per_class[0]), 4),\n",
    "            \"class_1\": round(float(val_recall_per_class[1]), 4),\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"macro\": round(val_f1_macro, 4),\n",
    "            \"class_0\": round(float(val_f1_per_class[0]), 4),\n",
    "            \"class_1\": round(float(val_f1_per_class[1]), 4),\n",
    "        },\n",
    "        \"auc_roc\": round(val_auc_roc, 4),\n",
    "    },\n",
    "    \"test_metrics\": {\n",
    "        \"accuracy\": round(test_accuracy, 4),\n",
    "        \"precision\": {\n",
    "            \"macro\": round(test_precision_macro, 4),\n",
    "            \"class_0\": round(float(test_precision_per_class[0]), 4),\n",
    "            \"class_1\": round(float(test_precision_per_class[1]), 4),\n",
    "        },\n",
    "        \"recall\": {\n",
    "            \"macro\": round(test_recall_macro, 4),\n",
    "            \"class_0\": round(float(test_recall_per_class[0]), 4),\n",
    "            \"class_1\": round(float(test_recall_per_class[1]), 4),\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"macro\": round(test_f1_macro, 4),\n",
    "            \"class_0\": round(float(test_f1_per_class[0]), 4),\n",
    "            \"class_1\": round(float(test_f1_per_class[1]), 4),\n",
    "        },\n",
    "        \"auc_roc\": round(test_auc_roc, 4),\n",
    "    },\n",
    "    \"confusion_matrix\": {\n",
    "        \"true_negative\": int(cm[0, 0]),\n",
    "        \"false_positive\": int(cm[0, 1]),\n",
    "        \"false_negative\": int(cm[1, 0]),\n",
    "        \"true_positive\": int(cm[1, 1]),\n",
    "    },\n",
    "}\n",
    "\n",
    "metrics_path = Path(\"../../metrics/logistic_regression_v2_metrics.json\")\n",
    "metrics_path = metrics_path.resolve()\n",
    "metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Metrics saved to: {metrics_path}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "## Comparison: V1 vs V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARISON: V1 (Baseline) vs V2 (Enriched Features)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>V1 Baseline</th>\n",
       "      <th>V2 Enriched</th>\n",
       "      <th>Improvement</th>\n",
       "      <th>Improvement %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>47.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision (macro)</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.7616</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>39.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall (macro)</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>44.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-Score (macro)</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.2563</td>\n",
       "      <td>49.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUC-ROC</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.3226</td>\n",
       "      <td>55.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  V1 Baseline  V2 Enriched  Improvement  Improvement %\n",
       "0           Accuracy       0.5502       0.8116       0.2614          47.51\n",
       "1  Precision (macro)       0.5441       0.7616       0.2175          39.97\n",
       "2     Recall (macro)       0.5572       0.8062       0.2490          44.69\n",
       "3   F1-Score (macro)       0.5196       0.7759       0.2563          49.33\n",
       "4            AUC-ROC       0.5770       0.8996       0.3226          55.91"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare with V1 baseline if available\n",
    "v1_metrics_path = Path(\"../../metrics/logistic_regression_metrics.json\")\n",
    "\n",
    "if v1_metrics_path.exists():\n",
    "    with open(v1_metrics_path, 'r') as f:\n",
    "        v1_metrics = json.load(f)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPARISON: V1 (Baseline) vs V2 (Enriched Features)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    comparison_data = {\n",
    "        \"Metric\": [\"Accuracy\", \"Precision (macro)\", \"Recall (macro)\", \"F1-Score (macro)\", \"AUC-ROC\"],\n",
    "        \"V1 Baseline\": [\n",
    "            v1_metrics[\"test_metrics\"][\"accuracy\"],\n",
    "            v1_metrics[\"test_metrics\"][\"precision\"][\"macro\"],\n",
    "            v1_metrics[\"test_metrics\"][\"recall\"][\"macro\"],\n",
    "            v1_metrics[\"test_metrics\"][\"f1\"][\"macro\"],\n",
    "            v1_metrics[\"test_metrics\"][\"auc_roc\"]\n",
    "        ],\n",
    "        \"V2 Enriched\": [\n",
    "            metrics[\"test_metrics\"][\"accuracy\"],\n",
    "            metrics[\"test_metrics\"][\"precision\"][\"macro\"],\n",
    "            metrics[\"test_metrics\"][\"recall\"][\"macro\"],\n",
    "            metrics[\"test_metrics\"][\"f1\"][\"macro\"],\n",
    "            metrics[\"test_metrics\"][\"auc_roc\"]\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_df[\"Improvement\"] = comparison_df[\"V2 Enriched\"] - comparison_df[\"V1 Baseline\"]\n",
    "    comparison_df[\"Improvement %\"] = (comparison_df[\"Improvement\"] / comparison_df[\"V1 Baseline\"] * 100).round(2)\n",
    "    \n",
    "    display(comparison_df)\n",
    "else:\n",
    "    print(\"V1 metrics not found. Run the baseline notebook first to compare.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01741e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf340090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

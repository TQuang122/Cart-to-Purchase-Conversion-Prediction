{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline Training\n",
    "## Customer Purchase Propensity Prediction\n",
    "\n",
    "This notebook trains a Logistic Regression model following the plan:\n",
    "1. Load data from Feast Feature Store (parquet file)\n",
    "2. Preprocessing: StandardScaler for numerical, OneHotEncoder for categorical\n",
    "3. Train/Val/Test split: 64%/16%/20%\n",
    "4. Regularization tuning on validation set\n",
    "5. Evaluate with Accuracy, Precision, Recall, F1, AUC-ROC\n",
    "6. Save metrics to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## 1. Load Data from Feast Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOGISTIC REGRESSION BASELINE TRAINING\n",
      "============================================================\n",
      "\n",
      "[1/6] Loading data from Feast Feature Store...\n",
      "Loading from: /Users/jky/Library/CloudStorage/GoogleDrive-lethanhquang094@gmail.com/My Drive/FPT/Semester_4/DAP391m/Cart-to-Purchase-Conversion-Prediction/data_pipeline/propensity_feature_store/propensity_features/feature_repo/data/processed_purchase_propensity_data_v1.parquet\n",
      "Dataset shape: (2933439, 11)\n",
      "Columns: ['user_id', 'product_id', 'event_timestamp', 'created_timestamp', 'category_code_level1', 'category_code_level2', 'brand', 'event_weekday', 'price', 'activity_count', 'is_purchased']\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LOGISTIC REGRESSION BASELINE TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n[1/6] Loading data from Feast Feature Store...\")\n",
    "\n",
    "# Define path - adjust based on notebook location\n",
    "parquet_path = Path(\"../../../data_pipeline/propensity_feature_store/propensity_features/feature_repo/data/processed_purchase_propensity_data_v1.parquet\")\n",
    "parquet_path = parquet_path.resolve()\n",
    "\n",
    "print(f\"Loading from: {parquet_path}\")\n",
    "df = pd.read_parquet(parquet_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "explore-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>created_timestamp</th>\n",
       "      <th>category_code_level1</th>\n",
       "      <th>category_code_level2</th>\n",
       "      <th>brand</th>\n",
       "      <th>event_weekday</th>\n",
       "      <th>price</th>\n",
       "      <th>activity_count</th>\n",
       "      <th>is_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>515903856</td>\n",
       "      <td>2601552</td>\n",
       "      <td>2019-11-17 00:11:39</td>\n",
       "      <td>2026-01-18 22:17:22.150556</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>gorenje</td>\n",
       "      <td>6</td>\n",
       "      <td>486.24</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>516301799</td>\n",
       "      <td>12702930</td>\n",
       "      <td>2019-11-12 15:40:15</td>\n",
       "      <td>2026-01-18 22:17:22.150556</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cordiant</td>\n",
       "      <td>1</td>\n",
       "      <td>35.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>516301799</td>\n",
       "      <td>12702930</td>\n",
       "      <td>2019-11-12 15:41:46</td>\n",
       "      <td>2026-01-18 22:17:22.150556</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cordiant</td>\n",
       "      <td>1</td>\n",
       "      <td>35.78</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516301799</td>\n",
       "      <td>12702930</td>\n",
       "      <td>2019-11-12 15:42:05</td>\n",
       "      <td>2026-01-18 22:17:22.150556</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>cordiant</td>\n",
       "      <td>1</td>\n",
       "      <td>35.78</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>561066382</td>\n",
       "      <td>3800966</td>\n",
       "      <td>2019-11-15 23:36:25</td>\n",
       "      <td>2026-01-18 22:17:22.150556</td>\n",
       "      <td>appliances</td>\n",
       "      <td>iron</td>\n",
       "      <td>elenberg</td>\n",
       "      <td>4</td>\n",
       "      <td>20.57</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  product_id     event_timestamp          created_timestamp  \\\n",
       "0  515903856     2601552 2019-11-17 00:11:39 2026-01-18 22:17:22.150556   \n",
       "1  516301799    12702930 2019-11-12 15:40:15 2026-01-18 22:17:22.150556   \n",
       "2  516301799    12702930 2019-11-12 15:41:46 2026-01-18 22:17:22.150556   \n",
       "3  516301799    12702930 2019-11-12 15:42:05 2026-01-18 22:17:22.150556   \n",
       "4  561066382     3800966 2019-11-15 23:36:25 2026-01-18 22:17:22.150556   \n",
       "\n",
       "  category_code_level1 category_code_level2     brand  event_weekday   price  \\\n",
       "0              unknown              unknown   gorenje              6  486.24   \n",
       "1              unknown              unknown  cordiant              1   35.78   \n",
       "2              unknown              unknown  cordiant              1   35.78   \n",
       "3              unknown              unknown  cordiant              1   35.78   \n",
       "4           appliances                 iron  elenberg              4   20.57   \n",
       "\n",
       "   activity_count  is_purchased  \n",
       "0               6             0  \n",
       "1               2             0  \n",
       "2               6             0  \n",
       "3               8             0  \n",
       "4               2             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "user_id                          int64\n",
      "product_id                       int64\n",
      "event_timestamp         datetime64[ns]\n",
      "created_timestamp       datetime64[us]\n",
      "category_code_level1            object\n",
      "category_code_level2            object\n",
      "brand                           object\n",
      "event_weekday                    int64\n",
      "price                          float64\n",
      "activity_count                   int64\n",
      "is_purchased                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Explore the data\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-header",
   "metadata": {},
   "source": [
    "## 2. Define Features and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "define-features",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/6] Preparing features and preprocessing pipeline...\n",
      "Numerical features: ['price', 'activity_count', 'event_weekday']\n",
      "Categorical features: ['brand', 'category_code_level1', 'category_code_level2']\n",
      "Target: is_purchased\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/6] Preparing features and preprocessing pipeline...\")\n",
    "\n",
    "NUMERICAL_FEATURES = [\"price\", \"activity_count\", \"event_weekday\"]\n",
    "CATEGORICAL_FEATURES = [\"brand\", \"category_code_level1\", \"category_code_level2\"]\n",
    "TARGET = \"is_purchased\"\n",
    "ALL_FEATURES = NUMERICAL_FEATURES + CATEGORICAL_FEATURES\n",
    "\n",
    "print(f\"Numerical features: {NUMERICAL_FEATURES}\")\n",
    "print(f\"Categorical features: {CATEGORICAL_FEATURES}\")\n",
    "print(f\"Target: {TARGET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prepare-xy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution:\n",
      "  Class 0 (Not Purchased): 2,170,105 (73.98%)\n",
      "  Class 1 (Purchased):     763,334 (26.02%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare X and y\n",
    "X = df[ALL_FEATURES].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "# Convert categorical columns to string type\n",
    "for col in CATEGORICAL_FEATURES:\n",
    "    X[col] = X[col].astype(str)\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Class 0 (Not Purchased): {(y == 0).sum():,} ({(y == 0).mean() * 100:.2f}%)\")\n",
    "print(f\"  Class 1 (Purchased):     {(y == 1).sum():,} ({(y == 1).mean() * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-header",
   "metadata": {},
   "source": [
    "## 3. Train/Validation/Test Split (64%/16%/20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "split-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/6] Splitting data (64%/16%/20%)...\n",
      "Training set:   1,877,400 samples (64.0%)\n",
      "Validation set: 469,351 samples (16.0%)\n",
      "Test set:       586,688 samples (20.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/6] Splitting data (64%/16%/20%)...\")\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 80% train, 20% val (of the 80% = 64% and 16% of total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"Training set:   {X_train.shape[0]:,} samples ({X_train.shape[0] / len(X) * 100:.1f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]:,} samples ({X_val.shape[0] / len(X) * 100:.1f}%)\")\n",
    "print(f\"Test set:       {X_test.shape[0]:,} samples ({X_test.shape[0] / len(X) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "create-preprocessor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor created!\n",
      "ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                 ['price', 'activity_count', 'event_weekday']),\n",
      "                                ('cat',\n",
      "                                 OneHotEncoder(handle_unknown='ignore',\n",
      "                                               max_categories=100,\n",
      "                                               sparse_output=False),\n",
      "                                 ['brand', 'category_code_level1',\n",
      "                                  'category_code_level2'])])\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUMERICAL_FEATURES),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(\n",
    "                handle_unknown=\"ignore\", sparse_output=False, max_categories=100\n",
    "            ),\n",
    "            CATEGORICAL_FEATURES,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "print(\"Preprocessor created!\")\n",
    "print(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tuning-header",
   "metadata": {},
   "source": [
    "## 4. Regularization Tuning on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tuning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/6] Tuning regularization parameter C...\n",
      "--------------------------------------------------\n",
      "\n",
      "Training with C=0.001... Done (4.7s)\n",
      "  Accuracy: 0.5572 | F1: 0.5238 | AUC-ROC: 0.5786\n",
      "\n",
      "Training with C=0.01... Done (4.6s)\n",
      "  Accuracy: 0.5536 | F1: 0.5219 | AUC-ROC: 0.5798\n",
      "\n",
      "Training with C=0.1... Done (5.2s)\n",
      "  Accuracy: 0.5520 | F1: 0.5212 | AUC-ROC: 0.5800\n",
      "\n",
      "Training with C=1... Done (5.1s)\n",
      "  Accuracy: 0.5522 | F1: 0.5213 | AUC-ROC: 0.5800\n",
      "\n",
      "Training with C=10... Done (4.6s)\n",
      "  Accuracy: 0.5524 | F1: 0.5214 | AUC-ROC: 0.5800\n",
      "\n",
      "Training with C=100... Done (5.3s)\n",
      "  Accuracy: 0.5520 | F1: 0.5211 | AUC-ROC: 0.5800\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/6] Tuning regularization parameter C...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "C_VALUES = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "tuning_results = []\n",
    "\n",
    "for C in C_VALUES:\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nTraining with C={C}...\", end=\" \", flush=True)\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\n",
    "                \"classifier\",\n",
    "                LogisticRegression(\n",
    "                    C=C,\n",
    "                    solver=\"lbfgs\",\n",
    "                    max_iter=1000,\n",
    "                    class_weight=\"balanced\",\n",
    "                    random_state=42,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = pipeline.predict(X_val)\n",
    "    y_val_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "    val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    result = {\n",
    "        \"C\": C,\n",
    "        \"accuracy\": val_accuracy,\n",
    "        \"f1_macro\": val_f1,\n",
    "        \"auc_roc\": val_auc,\n",
    "        \"pipeline\": pipeline,\n",
    "    }\n",
    "    tuning_results.append(result)\n",
    "\n",
    "    print(f\"Done ({elapsed:.1f}s)\")\n",
    "    print(f\"  Accuracy: {val_accuracy:.4f} | F1: {val_f1:.4f} | AUC-ROC: {val_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "select-best",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Best C: 100 (AUC-ROC: 0.5800)\n",
      "\n",
      "Tuning Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.557208</td>\n",
       "      <td>0.523770</td>\n",
       "      <td>0.578627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.553616</td>\n",
       "      <td>0.521938</td>\n",
       "      <td>0.579848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.552043</td>\n",
       "      <td>0.521151</td>\n",
       "      <td>0.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.552156</td>\n",
       "      <td>0.521264</td>\n",
       "      <td>0.580002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.552395</td>\n",
       "      <td>0.521355</td>\n",
       "      <td>0.579962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.551988</td>\n",
       "      <td>0.521118</td>\n",
       "      <td>0.580027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C  Accuracy  F1 Macro   AUC-ROC\n",
       "0    0.001  0.557208  0.523770  0.578627\n",
       "1    0.010  0.553616  0.521938  0.579848\n",
       "2    0.100  0.552043  0.521151  0.580002\n",
       "3    1.000  0.552156  0.521264  0.580002\n",
       "4   10.000  0.552395  0.521355  0.579962\n",
       "5  100.000  0.551988  0.521118  0.580027"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select best model\n",
    "best_result = max(tuning_results, key=lambda x: x[\"auc_roc\"])\n",
    "best_C = best_result[\"C\"]\n",
    "best_pipeline = best_result[\"pipeline\"]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(f\"Best C: {best_C} (AUC-ROC: {best_result['auc_roc']:.4f})\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nTuning Summary:\")\n",
    "tuning_df = pd.DataFrame([\n",
    "    {\"C\": r[\"C\"], \"Accuracy\": r[\"accuracy\"], \"F1 Macro\": r[\"f1_macro\"], \"AUC-ROC\": r[\"auc_roc\"]}\n",
    "    for r in tuning_results\n",
    "])\n",
    "display(tuning_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-training-header",
   "metadata": {},
   "source": [
    "## 5. Final Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "final-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/6] Final training on train+validation...\n",
      "Final training set: 2,346,751 samples\n",
      "Training complete (7.0s)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/6] Final training on train+validation...\")\n",
    "\n",
    "# Combine train and validation\n",
    "X_train_final = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_final = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "print(f\"Final training set: {len(X_train_final):,} samples\")\n",
    "\n",
    "# Create final pipeline\n",
    "final_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUMERICAL_FEATURES),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(\n",
    "                handle_unknown=\"ignore\", sparse_output=False, max_categories=100\n",
    "            ),\n",
    "            CATEGORICAL_FEATURES,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "final_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", final_preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LogisticRegression(\n",
    "                C=best_C,\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=1000,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "final_pipeline.fit(X_train_final, y_train_final)\n",
    "train_time = time.time() - start_time\n",
    "print(f\"Training complete ({train_time:.1f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "evaluate-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "\n",
      "==================================================\n",
      "TEST SET RESULTS\n",
      "==================================================\n",
      "Accuracy:  0.5502\n",
      "Precision: 0.5441 (macro)\n",
      "Recall:    0.5572 (macro)\n",
      "F1-Score:  0.5196 (macro)\n",
      "AUC-ROC:   0.5770\n",
      "\n",
      "Per-Class Metrics:\n",
      "  Class 0 (Not Purchased):\n",
      "    Precision: 0.7827\n",
      "    Recall:    0.5427\n",
      "    F1-Score:  0.6410\n",
      "  Class 1 (Purchased):\n",
      "    Precision: 0.3054\n",
      "    Recall:    0.5717\n",
      "    F1-Score:  0.3982\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "y_test_pred = final_pipeline.predict(X_test)\n",
    "y_test_proba = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate all metrics\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision_macro = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "test_recall_macro = recall_score(y_test, y_test_pred, average=\"macro\")\n",
    "test_f1_macro = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "test_auc_roc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "# Per-class metrics\n",
    "test_precision_per_class = precision_score(y_test, y_test_pred, average=None)\n",
    "test_recall_per_class = recall_score(y_test, y_test_pred, average=None)\n",
    "test_f1_per_class = f1_score(y_test, y_test_pred, average=None)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision_macro:.4f} (macro)\")\n",
    "print(f\"Recall:    {test_recall_macro:.4f} (macro)\")\n",
    "print(f\"F1-Score:  {test_f1_macro:.4f} (macro)\")\n",
    "print(f\"AUC-ROC:   {test_auc_roc:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Class Metrics:\")\n",
    "print(f\"  Class 0 (Not Purchased):\")\n",
    "print(f\"    Precision: {test_precision_per_class[0]:.4f}\")\n",
    "print(f\"    Recall:    {test_recall_per_class[0]:.4f}\")\n",
    "print(f\"    F1-Score:  {test_f1_per_class[0]:.4f}\")\n",
    "print(f\"  Class 1 (Purchased):\")\n",
    "print(f\"    Precision: {test_precision_per_class[1]:.4f}\")\n",
    "print(f\"    Recall:    {test_recall_per_class[1]:.4f}\")\n",
    "print(f\"    F1-Score:  {test_f1_per_class[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confusion-matrix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "  [[TN=235,540  FP=198,481]\n",
      "   [FN=65,385  TP=87,282]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Purchased       0.78      0.54      0.64    434021\n",
      "    Purchased       0.31      0.57      0.40    152667\n",
      "\n",
      "     accuracy                           0.55    586688\n",
      "    macro avg       0.54      0.56      0.52    586688\n",
      " weighted avg       0.66      0.55      0.58    586688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"  [[TN={cm[0, 0]:,}  FP={cm[0, 1]:,}]\")\n",
    "print(f\"   [FN={cm[1, 0]:,}  TP={cm[1, 1]:,}]]\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=[\"Not Purchased\", \"Purchased\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "validation-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Metrics (for comparison):\n",
      "  Accuracy:  0.5520\n",
      "  Precision: 0.5453 (macro)\n",
      "  Recall:    0.5587 (macro)\n",
      "  F1-Score:  0.5211 (macro)\n",
      "  AUC-ROC:   0.5800\n"
     ]
    }
   ],
   "source": [
    "# Get validation metrics for the best model\n",
    "y_val_pred_best = best_pipeline.predict(X_val)\n",
    "y_val_proba_best = best_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred_best)\n",
    "val_precision_macro = precision_score(y_val, y_val_pred_best, average=\"macro\")\n",
    "val_recall_macro = recall_score(y_val, y_val_pred_best, average=\"macro\")\n",
    "val_f1_macro = f1_score(y_val, y_val_pred_best, average=\"macro\")\n",
    "val_auc_roc = roc_auc_score(y_val, y_val_proba_best)\n",
    "\n",
    "val_precision_per_class = precision_score(y_val, y_val_pred_best, average=None)\n",
    "val_recall_per_class = recall_score(y_val, y_val_pred_best, average=None)\n",
    "val_f1_per_class = f1_score(y_val, y_val_pred_best, average=None)\n",
    "\n",
    "print(\"Validation Set Metrics (for comparison):\")\n",
    "print(f\"  Accuracy:  {val_accuracy:.4f}\")\n",
    "print(f\"  Precision: {val_precision_macro:.4f} (macro)\")\n",
    "print(f\"  Recall:    {val_recall_macro:.4f} (macro)\")\n",
    "print(f\"  F1-Score:  {val_f1_macro:.4f} (macro)\")\n",
    "print(f\"  AUC-ROC:   {val_auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 6. Save Metrics to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "save-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/6] Saving metrics to JSON...\n",
      "Metrics saved to: /Users/jky/Library/CloudStorage/GoogleDrive-lethanhquang094@gmail.com/My Drive/FPT/Semester_4/DAP391m/Cart-to-Purchase-Conversion-Prediction/model_pipeline/metrics/logistic_regression_metrics.json\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[6/6] Saving metrics to JSON...\")\n",
    "\n",
    "metrics = {\n",
    "    \"model\": \"LogisticRegression\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"hyperparameters\": {\n",
    "        \"best_C\": best_C,\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": 1000,\n",
    "        \"class_weight\": \"balanced\",\n",
    "    },\n",
    "    \"data_split\": {\n",
    "        \"train_size\": int(len(X_train)),\n",
    "        \"val_size\": int(len(X_val)),\n",
    "        \"test_size\": int(len(X_test)),\n",
    "        \"train_val_size\": int(len(X_train_final)),\n",
    "        \"total_size\": int(len(X)),\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"numerical\": NUMERICAL_FEATURES,\n",
    "        \"categorical\": CATEGORICAL_FEATURES,\n",
    "        \"preprocessing\": {\n",
    "            \"numerical\": \"StandardScaler\",\n",
    "            \"categorical\": \"OneHotEncoder (max_categories=100)\",\n",
    "        },\n",
    "    },\n",
    "    \"regularization_tuning\": [\n",
    "        {\n",
    "            \"C\": r[\"C\"],\n",
    "            \"val_accuracy\": round(r[\"accuracy\"], 4),\n",
    "            \"val_f1_macro\": round(r[\"f1_macro\"], 4),\n",
    "            \"val_auc_roc\": round(r[\"auc_roc\"], 4),\n",
    "        }\n",
    "        for r in tuning_results\n",
    "    ],\n",
    "    \"validation_metrics\": {\n",
    "        \"accuracy\": round(val_accuracy, 4),\n",
    "        \"precision\": {\n",
    "            \"macro\": round(val_precision_macro, 4),\n",
    "            \"class_0\": round(float(val_precision_per_class[0]), 4),\n",
    "            \"class_1\": round(float(val_precision_per_class[1]), 4),\n",
    "        },\n",
    "        \"recall\": {\n",
    "            \"macro\": round(val_recall_macro, 4),\n",
    "            \"class_0\": round(float(val_recall_per_class[0]), 4),\n",
    "            \"class_1\": round(float(val_recall_per_class[1]), 4),\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"macro\": round(val_f1_macro, 4),\n",
    "            \"class_0\": round(float(val_f1_per_class[0]), 4),\n",
    "            \"class_1\": round(float(val_f1_per_class[1]), 4),\n",
    "        },\n",
    "        \"auc_roc\": round(val_auc_roc, 4),\n",
    "    },\n",
    "    \"test_metrics\": {\n",
    "        \"accuracy\": round(test_accuracy, 4),\n",
    "        \"precision\": {\n",
    "            \"macro\": round(test_precision_macro, 4),\n",
    "            \"class_0\": round(float(test_precision_per_class[0]), 4),\n",
    "            \"class_1\": round(float(test_precision_per_class[1]), 4),\n",
    "        },\n",
    "        \"recall\": {\n",
    "            \"macro\": round(test_recall_macro, 4),\n",
    "            \"class_0\": round(float(test_recall_per_class[0]), 4),\n",
    "            \"class_1\": round(float(test_recall_per_class[1]), 4),\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"macro\": round(test_f1_macro, 4),\n",
    "            \"class_0\": round(float(test_f1_per_class[0]), 4),\n",
    "            \"class_1\": round(float(test_f1_per_class[1]), 4),\n",
    "        },\n",
    "        \"auc_roc\": round(test_auc_roc, 4),\n",
    "    },\n",
    "    \"confusion_matrix\": {\n",
    "        \"true_negative\": int(cm[0, 0]),\n",
    "        \"false_positive\": int(cm[0, 1]),\n",
    "        \"false_negative\": int(cm[1, 0]),\n",
    "        \"true_positive\": int(cm[1, 1]),\n",
    "    },\n",
    "}\n",
    "\n",
    "metrics_path = Path(\"../../metrics/logistic_regression_metrics.json\")\n",
    "metrics_path = metrics_path.resolve()\n",
    "metrics_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(metrics_path, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Metrics saved to: {metrics_path}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "display-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Metrics Summary:\n",
      "{\n",
      "  \"model\": \"LogisticRegression\",\n",
      "  \"timestamp\": \"2026-01-21T10:15:43.345103\",\n",
      "  \"hyperparameters\": {\n",
      "    \"best_C\": 100,\n",
      "    \"solver\": \"lbfgs\",\n",
      "    \"max_iter\": 1000,\n",
      "    \"class_weight\": \"balanced\"\n",
      "  },\n",
      "  \"data_split\": {\n",
      "    \"train_size\": 1877400,\n",
      "    \"val_size\": 469351,\n",
      "    \"test_size\": 586688,\n",
      "    \"train_val_size\": 2346751,\n",
      "    \"total_size\": 2933439\n",
      "  },\n",
      "  \"features\": {\n",
      "    \"numerical\": [\n",
      "      \"price\",\n",
      "      \"activity_count\",\n",
      "      \"event_weekday\"\n",
      "    ],\n",
      "    \"categorical\": [\n",
      "      \"brand\",\n",
      "      \"category_code_level1\",\n",
      "      \"category_code_level2\"\n",
      "    ],\n",
      "    \"preprocessing\": {\n",
      "      \"numerical\": \"StandardScaler\",\n",
      "      \"categorical\": \"OneHotEncoder (max_categories=100)\"\n",
      "    }\n",
      "  },\n",
      "  \"regularization_tuning\": [\n",
      "    {\n",
      "      \"C\": 0.001,\n",
      "      \"val_accuracy\": 0.5572,\n",
      "      \"val_f1_macro\": 0.5238,\n",
      "      \"val_auc_roc\": 0.5786\n",
      "    },\n",
      "    {\n",
      "      \"C\": 0.01,\n",
      "      \"val_accuracy\": 0.5536,\n",
      "      \"val_f1_macro\": 0.5219,\n",
      "      \"val_auc_roc\": 0.5798\n",
      "    },\n",
      "    {\n",
      "      \"C\": 0.1,\n",
      "      \"val_accuracy\": 0.552,\n",
      "      \"val_f1_macro\": 0.5212,\n",
      "      \"val_auc_roc\": 0.58\n",
      "    },\n",
      "    {\n",
      "      \"C\": 1,\n",
      "      \"val_accuracy\": 0.5522,\n",
      "      \"val_f1_macro\": 0.5213,\n",
      "      \"val_auc_roc\": 0.58\n",
      "    },\n",
      "    {\n",
      "      \"C\": 10,\n",
      "      \"val_accuracy\": 0.5524,\n",
      "      \"val_f1_macro\": 0.5214,\n",
      "      \"val_auc_roc\": 0.58\n",
      "    },\n",
      "    {\n",
      "      \"C\": 100,\n",
      "      \"val_accuracy\": 0.552,\n",
      "      \"val_f1_macro\": 0.5211,\n",
      "      \"val_auc_roc\": 0.58\n",
      "    }\n",
      "  ],\n",
      "  \"validation_metrics\": {\n",
      "    \"accuracy\": 0.552,\n",
      "    \"precision\": {\n",
      "      \"macro\": 0.5453,\n",
      "      \"class_0\": 0.7838,\n",
      "      \"class_1\": 0.3068\n",
      "    },\n",
      "    \"recall\": {\n",
      "      \"macro\": 0.5587,\n",
      "      \"class_0\": 0.5447,\n",
      "      \"class_1\": 0.5728\n",
      "    },\n",
      "    \"f1\": {\n",
      "      \"macro\": 0.5211,\n",
      "      \"class_0\": 0.6427,\n",
      "      \"class_1\": 0.3995\n",
      "    },\n",
      "    \"auc_roc\": 0.58\n",
      "  },\n",
      "  \"test_metrics\": {\n",
      "    \"accuracy\": 0.5502,\n",
      "    \"precision\": {\n",
      "      \"macro\": 0.5441,\n",
      "      \"class_0\": 0.7827,\n",
      "      \"class_1\": 0.3054\n",
      "    },\n",
      "    \"recall\": {\n",
      "      \"macro\": 0.5572,\n",
      "      \"class_0\": 0.5427,\n",
      "      \"class_1\": 0.5717\n",
      "    },\n",
      "    \"f1\": {\n",
      "      \"macro\": 0.5196,\n",
      "      \"class_0\": 0.641,\n",
      "      \"class_1\": 0.3982\n",
      "    },\n",
      "    \"auc_roc\": 0.577\n",
      "  },\n",
      "  \"confusion_matrix\": {\n",
      "    \"true_negative\": 235540,\n",
      "    \"false_positive\": 198481,\n",
      "    \"false_negative\": 65385,\n",
      "    \"true_positive\": 87282\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Display final metrics\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "print(json.dumps(metrics, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2def9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae5f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79aba16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82bc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79bdfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
